{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: What is labelled data worth to Naive Bayes?\n",
    "---\n",
    "###### Student Name(s): Maleakhi Agung Wijaya, Chirag Rao Sahib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Path Constant\n",
    "BREAST_CANCER = \"2018S1-proj1_data/breast-cancer-dos.csv\"\n",
    "CAR = \"2018S1-proj1_data/car-dos.csv\"\n",
    "HYPOTHYROID = \"2018S1-proj1_data/hypothyroid-dos.csv\"\n",
    "MUSHROOM = \"2018S1-proj1_data/mushroom-dos.csv\"\n",
    "\n",
    "# Column name for each data set\n",
    "BREAST_CANCER_COLUMN = [\"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"node-caps\", \"deg-malig\", \"breast\", \"breast-quad\", \"irradiat\", \"class\"]\n",
    "CAR_COLUMN = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "HYPOTHYROID_COLUMN = [\"sex\", \"on_thyroxine\", \"query_on_thyroxine\", \"on_antithyroid_medication\", \"thyroid_surgery\", \"query_hypothyroid\", \"query_hyperthyroid\", \"pregnant\", \"sick\", \"tumor\", \"lithium\", \"goitre\", \"TSH_measured\", \"T3_measured\", \"TT4_measured\", \"T4U_measured\", \"FTI_measured\", \"TBG_measured\", \"class\"]\n",
    "MUSHROOM_COLUMN = [\"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\", \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\", \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"ring-number\", \"ring-type\", \"spore-print-color\", \"population\", \"habitat\", \"class\"]\n",
    "\n",
    "# Other Constant\n",
    "PRIOR_INDEX = 0\n",
    "POSTERIOR_INDEX = 1\n",
    "EPSILON = 0.000001 # Epsilon smoothing\n",
    "ITERATION = 2 # Number of iteration in unsupervised naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Used to check algorithm correctness\n",
    "training_df = pd.DataFrame(data={\"Headache\": [\"severe\", \"no\", \"mild\", \"mild\", \"severe\"], \"Sore\": [\"mild\", \"severe\", \"mild\", \"no\", \"severe\"], \"Temperature\":[\"high\", \"normal\", \"normal\", \"normal\", \"normal\"], \"Cough\": [\"yes\", \"yes\", \"yes\", \"no\", \"yes\"], \"class\":[\"flu\", \"cold\", \"flu\", \"cold\", \"flu\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "# @param data = csv data that will be opened\n",
    "# @param columns = new column name for header\n",
    "# @param eliminate = eliminate the missing/ ? instances (recommended if there are only few ? instances)\n",
    "# @return df = clean pandas dataframe object\n",
    "def preprocess(data, columns, eliminate=True):\n",
    "    # Read and add a header to the data frame\n",
    "    df = pd.read_csv(data, header=None)\n",
    "    df.columns = columns\n",
    "    \n",
    "    # If the parameter ignore is set to be false then we don't ignore\n",
    "    if (eliminate):\n",
    "        # Iterate through the dataframe and only append without missing value\n",
    "        # Capture the index of one with the missing values\n",
    "        for index, row in df.iterrows():\n",
    "            for att in row:\n",
    "                # If encounter missing values in the data, don't use that\n",
    "                if (att == \"?\"):\n",
    "                    df.drop(index, inplace=True)\n",
    "                    break\n",
    "    \n",
    "    # Return the clean data\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should build a supervised NB model and return a count\n",
    "# @param train_data = training data that are used to create the supervised NB classifier\n",
    "# @param class_label = column name of the class that we want to classify\n",
    "# @return count_prior = dictionary describing prior count of the class in training data\n",
    "# @return count_posterior = dictionary of dictionaries posterior count\n",
    "def train_count_supervised(train_data, class_label):\n",
    "    # Calculate prior (dictionary_prior)\n",
    "    # Initiate python dictionary with the number of class in the training data as it's key\n",
    "    count_prior = {}\n",
    "    for unique_class in train_data[class_label].unique():\n",
    "        count_prior[unique_class] = 0\n",
    "    \n",
    "    # Loop through the training data and get how many for every classes instance.\n",
    "    # Now we have the count prior class that are used for prediction\n",
    "    for index, row in train_data.iterrows():\n",
    "        count_prior[row[class_label]] += 1\n",
    "    \n",
    "    # Calculate count posterior (dictionary_posterior), the data structure used are dictionary\n",
    "    # of dictionary of dictionaries\n",
    "    count_posterior = {}\n",
    "    \n",
    "    # Setup the dictionary component\n",
    "    column_name = list(train_data.columns)\n",
    "    column_name.remove(class_label)\n",
    "    for col in column_name:\n",
    "        count_posterior[col] = {}\n",
    "        for unique_class in train_data[class_label].unique():\n",
    "            count_posterior[col][unique_class] = {}\n",
    "            for unique_col in train_data[col].unique():\n",
    "                count_posterior[col][unique_class][unique_col] = 0\n",
    "    \n",
    "    # Now use the training data to perform calculation\n",
    "    for index, row in train_data.iterrows():\n",
    "        for col in column_name:\n",
    "            count_posterior[col][row[class_label]][row[col]] += 1\n",
    "            \n",
    "    return((count_prior, count_posterior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should build supervised NB model and return a probability\n",
    "# @param train_data = training data that are used to create the supervised NB classifier\n",
    "# @param class_label = column name of the class that we want to classify\n",
    "# @return probability_prior = dictionary describing prior probability of the class in training data,\n",
    "# @return probability_posterior = dictionary of dictionaries posterior probability\n",
    "def train_probability_supervised(train_data, class_label):\n",
    "    (count_prior, count_posterior) = train_count_supervised(train_data, class_label)\n",
    "    \n",
    "    # Now calculate the probability of each instances, (i.e. 'Cough': {'flu': {'yes': 3, 'no': 0}, 'cold': {'yes': 1, 'no': 1}}\n",
    "    # will have P(cough = yes | flu) = 3/3, P(cough = no | flu) = 0/3 and P(cough = yes | cold) = 1/2, P(cough = no | cold) = 1/2\n",
    "    \n",
    "    # First calculate the prior probability of the class P(c)\n",
    "    probability_prior = {}\n",
    "    sum_instance = sum(count_prior.values())\n",
    "    for unique_class in train_data[class_label].unique():\n",
    "        probability_prior[unique_class] = count_prior[unique_class] / sum_instance\n",
    "        \n",
    "        # Perform epsilon smoothing\n",
    "        if (count_prior[unique_class] == 0):\n",
    "            probability_prior[unique_class] = EPSILON\n",
    "    \n",
    "    # Calculate the posterior probability\n",
    "    probability_posterior = count_posterior\n",
    "    column_name = list(train_data.columns)\n",
    "    column_name.remove(class_label)\n",
    "                \n",
    "    # Now calculate the posterior probability\n",
    "    for col in column_name:\n",
    "        for unique_class in train_data[class_label].unique():\n",
    "            sum_instance = sum(probability_posterior[col][unique_class].values())\n",
    "            for unique_col in train_data[col].unique():\n",
    "                probability_posterior[col][unique_class][unique_col] /= sum_instance\n",
    "                \n",
    "                # Perform epsilon smoothing\n",
    "                if (probability_posterior[col][unique_class][unique_col] == 0):\n",
    "                    probability_posterior[col][unique_class][unique_col] = EPSILON\n",
    "                \n",
    "            \n",
    "    return((probability_prior, probability_posterior))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should predict the class for a set of instances, based on a trained model \n",
    "# @param test_data = data to be tested\n",
    "# @param train_data = data used for setup such as finding all possible classes\n",
    "# @param class_label = attribute that we want to classify using naive bayes\n",
    "# @param model = tuple consisting probability_prior and probability_posterior. \n",
    "# Mainly use the train_probability_supervised instead of train_count_supervised\n",
    "# @return test_class = the class predicted by the naive bayes classifier\n",
    "def predict_supervised(test_data, train_data, class_label, model):\n",
    "    prior_probability = model[PRIOR_INDEX]\n",
    "    posterior_probability = model[POSTERIOR_INDEX]\n",
    "    test_class = [] # used to capture test result\n",
    "    \n",
    "    # Used for calculation purposes\n",
    "    column_name = list(train_data.columns)\n",
    "    column_name.remove(class_label)\n",
    "    \n",
    "    # Get the answer for every test instance\n",
    "    for index, row in test_data.iterrows():\n",
    "        # Initiate dictionary capturing the values calculated by naive bayes model\n",
    "        test_value = {}\n",
    "        for unique_class in train_data[class_label].unique():\n",
    "            test_value[unique_class] = 0\n",
    "\n",
    "        # Calculate for each class using the naive bayes model (log model for multiplication)\n",
    "        for unique_class in train_data[class_label].unique():\n",
    "            test_value[unique_class] = np.log(prior_probability[unique_class])\n",
    "            for col in column_name:\n",
    "                test_value[unique_class] += np.log(posterior_probability[col][unique_class][row[col]])\n",
    "            \n",
    "        # After calculating all of the possible class, we want to choose the maximum\n",
    "        maximum_class = (train_data[class_label].unique())[0]\n",
    "        maximum_value = test_value[maximum_class]\n",
    "        for key, value in test_value.items():\n",
    "            if (value > maximum_value):\n",
    "                maximum_value = value\n",
    "                maximum_class = key\n",
    "    \n",
    "        # Append result\n",
    "        test_class.append(maximum_class)\n",
    "    \n",
    "    # Return the classifier for the class\n",
    "    return test_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context \n",
    "def evaluate_supervised(true_test_result, predicted_test_result):\n",
    "    if (len(true_test_result) != len(predicted_test_result)):\n",
    "        print(\"Error, different length.\")\n",
    "    else:\n",
    "        # Measure accuracy\n",
    "        correct = 0\n",
    "        for i in range(len(true_test_result)):\n",
    "            if (true_test_result[i] == predicted_test_result[i]):\n",
    "                correct += 1\n",
    "            \n",
    "        accuracy = correct / len(true_test_result)\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_supervised(true_test_result, predicted_test_result, class_column):\n",
    "    if (len(true_test_result) != len(predicted_test_result)):\n",
    "        print(\"Error, different length.\")\n",
    "    else:\n",
    "        # Create a pandas dataframe actual is the row, predicted is the column\n",
    "        confusion_df = pd.DataFrame()\n",
    "        \n",
    "        for unique_class in class_column:\n",
    "            confusion_df[unique_class] = [0 for i in range(len(class_column))]\n",
    "        \n",
    "        # Change index for df\n",
    "        confusion_df.index = class_column\n",
    "        \n",
    "        # Calculate the confusion matrix\n",
    "        for i in range(len(true_test_result)):\n",
    "            confusion_df.loc[true_test_result[i], predicted_test_result[i]] += 1\n",
    "            \n",
    "        # Add actual and predicted description on the table to make it easier to see\n",
    "        predicted_column = []\n",
    "        for string in confusion_df.columns:\n",
    "            string += \" predicted\"\n",
    "            predicted_column.append(string.title())\n",
    "       \n",
    "        actual_row = []\n",
    "        for string in class_column:\n",
    "            string += \" actual\"\n",
    "            actual_row.append(string.title())\n",
    "        \n",
    "        confusion_df.columns = predicted_column\n",
    "        confusion_df.index = actual_row\n",
    "        \n",
    "        return confusion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recurrence-Events Predicted</th>\n",
       "      <th>No-Recurrence-Events Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Recurrence-Events Actual</th>\n",
       "      <td>48</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No-Recurrence-Events Actual</th>\n",
       "      <td>31</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Recurrence-Events Predicted  \\\n",
       "Recurrence-Events Actual                              48   \n",
       "No-Recurrence-Events Actual                           31   \n",
       "\n",
       "                             No-Recurrence-Events Predicted  \n",
       "Recurrence-Events Actual                                 33  \n",
       "No-Recurrence-Events Actual                             165  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for breast cancer dataset is 0.7689530685920578.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unacc Predicted</th>\n",
       "      <th>Acc Predicted</th>\n",
       "      <th>Vgood Predicted</th>\n",
       "      <th>Good Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unacc Actual</th>\n",
       "      <td>1161</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Acc Actual</th>\n",
       "      <td>85</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vgood Actual</th>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good Actual</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unacc Predicted  Acc Predicted  Vgood Predicted  Good Predicted\n",
       "Unacc Actual             1161             47                0               2\n",
       "Acc Actual                 85            289                0              10\n",
       "Vgood Actual                0             26               39               0\n",
       "Good Actual                 0             46                2              21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for car dataset is 0.8738425925925926.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hypothyroid Predicted</th>\n",
       "      <th>Negative Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hypothyroid Actual</th>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Actual</th>\n",
       "      <td>0</td>\n",
       "      <td>2941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Hypothyroid Predicted  Negative Predicted\n",
       "Hypothyroid Actual                      0                 149\n",
       "Negative Actual                         0                2941"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for hypothyroid dataset is 0.9517799352750809.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P Predicted</th>\n",
       "      <th>E Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P Actual</th>\n",
       "      <td>2156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E Actual</th>\n",
       "      <td>16</td>\n",
       "      <td>3472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          P Predicted  E Predicted\n",
       "P Actual         2156            0\n",
       "E Actual           16         3472"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for mushroom dataset is 0.997165131112686.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the breast cancer data\n",
    "df_breast_cancer = preprocess(BREAST_CANCER, BREAST_CANCER_COLUMN, eliminate=True)\n",
    "model_main = train_probability_supervised(df_breast_cancer, \"class\")\n",
    "predicted_test_result = predict_supervised(df_breast_cancer, df_breast_cancer, \"class\", model_main)\n",
    "confusion_df = confusion_matrix_supervised(list(df_breast_cancer[\"class\"]), predicted_test_result, df_breast_cancer[\"class\"].unique())\n",
    "display(confusion_df)\n",
    "print(\"The accuracy for breast cancer dataset is {}.\".format(evaluate_supervised(list(df_breast_cancer[\"class\"]), predicted_test_result)))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Using car data\n",
    "df_car = preprocess(CAR, CAR_COLUMN, eliminate=True)\n",
    "model_main = train_probability_supervised(df_car, \"class\")\n",
    "predicted_test_result = predict_supervised(df_car, df_car, \"class\", model_main)\n",
    "confusion_df = confusion_matrix_supervised(list(df_car[\"class\"]), predicted_test_result, df_car[\"class\"].unique())\n",
    "display(confusion_df)\n",
    "print(\"The accuracy for car dataset is {}.\".format(evaluate_supervised(list(df_car[\"class\"]), predicted_test_result)))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Using the breast cancer data\n",
    "df_hypo = preprocess(HYPOTHYROID, HYPOTHYROID_COLUMN, eliminate=True)\n",
    "model_main = train_probability_supervised(df_hypo, \"class\")\n",
    "predicted_test_result = predict_supervised(df_hypo, df_hypo, \"class\", model_main)\n",
    "confusion_df = confusion_matrix_supervised(list(df_hypo[\"class\"]), predicted_test_result, df_hypo[\"class\"].unique())\n",
    "display(confusion_df)\n",
    "print(\"The accuracy for hypothyroid dataset is {}.\".format(evaluate_supervised(list(df_hypo[\"class\"]), predicted_test_result)))\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Using the breast cancer data\n",
    "df_mushroom = preprocess(MUSHROOM, MUSHROOM_COLUMN, eliminate=True)\n",
    "model_main = train_probability_supervised(df_mushroom, \"class\")\n",
    "predicted_test_result = predict_supervised(df_mushroom, df_mushroom, \"class\", model_main)\n",
    "confusion_df = confusion_matrix_supervised(list(df_mushroom[\"class\"]), predicted_test_result, df_mushroom[\"class\"].unique())\n",
    "display(confusion_df)\n",
    "print(\"The accuracy for mushroom dataset is {}.\".format(evaluate_supervised(list(df_mushroom[\"class\"]), predicted_test_result)))\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function initialise the distribution randomly to the dataframe to begin the unsupervised\n",
    "# calculation.\n",
    "# @param dataset = dataframe of the dataset\n",
    "# @param class_label = class that we will use the classification on\n",
    "# @return unsupervised_dataset = dataset that have been appended by the distribution columns\n",
    "def initialise_unsupervised_naive_bayes(dataset, class_label):\n",
    "    # First remove the class label and put that on the columns so that we can assign a distribution\n",
    "    class_column = list(dataset[class_label].unique())\n",
    "    last_class = class_column[-1]\n",
    "    unsupervised_dataset = dataset.drop([\"class\"], axis=1)\n",
    "    \n",
    "    # Add a column to the dataset according to random distribution (initialisation phase)\n",
    "    row_instance = unsupervised_dataset.shape[0]\n",
    "    for unique_class in class_column:\n",
    "        unsupervised_dataset[unique_class] = [0 for i in range(row_instance)]\n",
    "    \n",
    "    # Add random value to the dataset\n",
    "    for index, row in unsupervised_dataset.iterrows():\n",
    "        max_probability = 1\n",
    "        for unique_class in class_column:\n",
    "            # Assign the remaining probability to the last class\n",
    "            if (unique_class == last_class):\n",
    "                unsupervised_dataset.loc[index, unique_class] = max_probability\n",
    "            else:\n",
    "                unsupervised_dataset.loc[index, unique_class] = random.uniform(0, max_probability)\n",
    "                max_probability -= unsupervised_dataset.loc[index, unique_class]\n",
    "    \n",
    "    return unsupervised_dataset\n",
    "    \n",
    "# unsupervised_df = initialise_unsupervised_naive_bayes(training_df, \"class\")\n",
    "# print(unsupervised_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should build an unsupervised NB model and return a count\n",
    "# @param class_column = possible class name (weak unsupervised model)\n",
    "# @param attribute_column = attributes that are used for calculation\n",
    "# @param dataset = data that are used to create the unsupervised NB classifier (format after running initialise_unsupervised_naive_bayes function)\n",
    "# @param class_label = column name of the class that we want to classify\n",
    "# @return count_prior = dictionary describing prior count of the class in training data\n",
    "# @return count_posterior = dictionary of dictionaries posterior count\n",
    "def train_count_unsupervised(class_column, attribute_column, dataset, class_label):\n",
    "    # Calculate prior (dictionary_prior)\n",
    "    # Initiate python dictionary with the number of class in the training data as it's key\n",
    "    count_prior = {}\n",
    "    for unique_class in class_column:\n",
    "        count_prior[unique_class] = 0\n",
    "    \n",
    "    # Loop through the training data and sum the probability\n",
    "    for index, row in dataset.iterrows():\n",
    "        for unique_class in class_column:\n",
    "            count_prior[unique_class] += row[unique_class]\n",
    "    \n",
    "    # Calculate count posterior (dictionary_posterior), the data structure used are dictionary\n",
    "    # of dictionary of dictionaries\n",
    "    count_posterior = {}\n",
    "    \n",
    "    # Setup the dictionary component\n",
    "    for col in attribute_column:\n",
    "        count_posterior[col] = {}\n",
    "        for unique_class in class_column:\n",
    "            count_posterior[col][unique_class] = {}\n",
    "            for unique_col in dataset[col].unique():\n",
    "                count_posterior[col][unique_class][unique_col] = 0\n",
    "    \n",
    "    # Now use the training data to perform calculation\n",
    "    for index, row in dataset.iterrows():\n",
    "        for col in attribute_column:\n",
    "            for unique_class in class_column:\n",
    "                count_posterior[col][unique_class][row[col]] += row[unique_class]\n",
    "   \n",
    "    return((count_prior, count_posterior))\n",
    "\n",
    "# attribute_column = list(training_df.columns)\n",
    "# attribute_column.remove(\"class\")\n",
    "# train_count_unsupervised(training_df[\"class\"].unique(), attribute_column, unsupervised_df, \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should build unsupervised NB model and return a probability\n",
    "# @param class_column = possible class name (weak unsupervised model)\n",
    "# @param attribute_column = attributes that are used for calculation\n",
    "# @param dataset = data that are used to create the unsupervised NB classifier (format after running initialise_unsupervised_naive_bayes function)\n",
    "# @param class_label = column name of the class that we want to classify\n",
    "# @return probability_prior = dictionary describing prior probability of the class in training data,\n",
    "# @return probability_posterior = dictionary of dictionaries posterior probability\n",
    "def train_probability_unsupervised(class_column, attribute_column, dataset, class_label):\n",
    "    (count_prior, count_posterior) = train_count_unsupervised(class_column, attribute_column, dataset, class_label)\n",
    "    \n",
    "    # Now calculate the probability of each instances, (i.e. 'Cough': {'flu': {'yes': 0.3, 'no': 0}, 'cold': {'yes': 0.1, 'no': 0.1}}\n",
    "    # will have P(cough = yes | flu) = 0.3/0.3, P(cough = no | flu) = 0/0.3 and P(cough = yes | cold) = 0.1/0.2, P(cough = no | cold) = 0.1/0.2\n",
    "    \n",
    "    # First calculate the prior probability of the class P(c)\n",
    "    probability_prior = {}\n",
    "    sum_instance = sum(count_prior.values())\n",
    "    for unique_class in class_column:\n",
    "        probability_prior[unique_class] = count_prior[unique_class] / sum_instance\n",
    "        \n",
    "        # Perform epsilon smoothing\n",
    "        if (count_prior[unique_class] == 0.0):\n",
    "            probability_prior[unique_class] = EPSILON\n",
    "\n",
    "    # Calculate the posterior probability\n",
    "    probability_posterior = count_posterior\n",
    "                \n",
    "    # Now calculate the posterior probability\n",
    "    for col in attribute_column:\n",
    "        for unique_class in class_column:\n",
    "            sum_instance = sum(probability_posterior[col][unique_class].values())\n",
    "            for unique_col in dataset[col].unique():\n",
    "                probability_posterior[col][unique_class][unique_col] /= sum_instance\n",
    "                \n",
    "                # Perform epsilon smoothing\n",
    "                if (probability_posterior[col][unique_class][unique_col] == 0):\n",
    "                    probability_posterior[col][unique_class][unique_col] = EPSILON\n",
    "          \n",
    "    return((probability_prior, probability_posterior))\n",
    "\n",
    "# attribute_column = list(training_df.columns)\n",
    "# attribute_column.remove(\"class\")\n",
    "# model = train_probability_unsupervised(training_df[\"class\"].unique(), attribute_column, unsupervised_df, \"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should predict the class for a set of instances, based on a trained model \n",
    "# @param dataset = data that are used to calculate prediction\n",
    "# @param class_column = possible class name (weak unsupervised model)\n",
    "# @param attribute_column = attributes that are used for calculation\n",
    "# @param class_label = attribute that we want to classify using naive bayes\n",
    "# @param model = tuple consisting probability_prior and probability_posterior. \n",
    "# @return test_class = the class predicted by the naive bayes classifier. The predict class will change the structure of dataset to be used for the next iteration.\n",
    "def predict_unsupervised(dataset, class_column, attribute_column, class_label, model):\n",
    "    prior_probability = model[PRIOR_INDEX]\n",
    "    posterior_probability = model[POSTERIOR_INDEX]\n",
    "    test_class = [] # used to capture test result\n",
    "    \n",
    "    # Get the answer for every test instance\n",
    "    for index, row in dataset.iterrows():\n",
    "        # Initiate dictionary capturing the values calculated by naive bayes model\n",
    "        test_value = {}\n",
    "        for unique_class in class_column:\n",
    "            test_value[unique_class] = 0\n",
    "\n",
    "        # Calculate for each class using the naive bayes model (log model for multiplication)\n",
    "        for unique_class in class_column:\n",
    "            test_value[unique_class] = np.log(prior_probability[unique_class])\n",
    "            for col in attribute_column:\n",
    "                test_value[unique_class] += np.log(posterior_probability[col][unique_class][row[col]])\n",
    "            \n",
    "        # After calculating all of the possible class, we want to choose the maximum\n",
    "        maximum_class = class_column[0]\n",
    "        maximum_value = test_value[maximum_class]\n",
    "        for key, value in test_value.items():\n",
    "            if (value > maximum_value):\n",
    "                maximum_value = value\n",
    "                maximum_class = key\n",
    "    \n",
    "        # Append result\n",
    "        test_class.append(maximum_class)\n",
    "        \n",
    "        # Change the dataset structure for the instance to prepare for the next iteration\n",
    "        # First take the exponent of that to get the real probability calculation value\n",
    "        for unique_class in class_column:\n",
    "            test_value[unique_class] = np.exp(test_value[unique_class])\n",
    "        \n",
    "        # Calculate the new probability\n",
    "        denominator_new = sum(test_value.values())\n",
    "        for unique_class in class_column:\n",
    "            dataset.loc[index, unique_class] = test_value[unique_class] / denominator_new\n",
    "    \n",
    "    # Return the classifier for the class\n",
    "    return test_class\n",
    "\n",
    "# attribute_column = list(training_df.columns)\n",
    "# attribute_column.remove(\"class\")\n",
    "# print(predict_unsupervised(unsupervised_df, training_df[\"class\"].unique(), attribute_column, \"class\", model ))\n",
    "# print(unsupervised_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in an unsupervised context (create confusion matrix)\n",
    "# @param true_test_result = list displaying the real value of the test result\n",
    "# @param predicted_test_result = list displaying the prediction\n",
    "# @param class_column = all possible classes\n",
    "def evaluate_unsupervised(true_test_result, predicted_test_result, class_column):\n",
    "    if (len(true_test_result) != len(predicted_test_result)):\n",
    "        print(\"Error, different length.\")\n",
    "    else:\n",
    "        # Create a pandas dataframe actual is the row, predicted is the column\n",
    "        confusion_df = pd.DataFrame()\n",
    "        \n",
    "        for unique_class in class_column:\n",
    "            confusion_df[unique_class] = [0 for i in range(len(class_column))]\n",
    "        \n",
    "        # Change index for df\n",
    "        confusion_df.index = class_column\n",
    "        \n",
    "        # Calculate the confusion matrix\n",
    "        for i in range(len(true_test_result)):\n",
    "            confusion_df.loc[true_test_result[i], predicted_test_result[i]] += 1\n",
    "            \n",
    "        # Add actual and predicted description on the table to make it easier to see\n",
    "        predicted_column = []\n",
    "        for string in confusion_df.columns:\n",
    "            string += \" predicted\"\n",
    "            predicted_column.append(string.title())\n",
    "       \n",
    "        actual_row = []\n",
    "        for string in class_column:\n",
    "            string += \" actual\"\n",
    "            actual_row.append(string.title())\n",
    "        \n",
    "        confusion_df.columns = predicted_column\n",
    "        confusion_df.index = actual_row\n",
    "        \n",
    "        return confusion_df\n",
    "\n",
    "# predicted_test_result = predict_unsupervised(unsupervised_df, training_df[\"class\"].unique(), attribute_column, \"class\", model)\n",
    "# confusion_df = evaluate_unsupervised([\"flu\", \"cold\", \"flu\", \"cold\", \"flu\"], predicted_test_result, [\"cold\", \"flu\"])\n",
    "# display(confusion_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cough</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Sore</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>flu</th>\n",
       "      <th>cold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>severe</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>severe</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>severe</td>\n",
       "      <td>severe</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cough Headache    Sore Temperature  flu  cold\n",
       "0   yes   severe    mild        high  0.6   0.4\n",
       "1   yes       no  severe      normal  0.3   0.7\n",
       "2   yes     mild    mild      normal  0.1   0.9\n",
       "3    no     mild      no      normal  0.8   0.2\n",
       "4   yes   severe  severe      normal  0.4   0.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cough</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Sore</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>flu</th>\n",
       "      <th>cold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>severe</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>0.472745</td>\n",
       "      <td>0.527255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>severe</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.145872</td>\n",
       "      <td>0.854128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.245876</td>\n",
       "      <td>0.754124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.947347</td>\n",
       "      <td>0.052653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>severe</td>\n",
       "      <td>severe</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.284946</td>\n",
       "      <td>0.715054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cough Headache    Sore Temperature       flu      cold\n",
       "0   yes   severe    mild        high  0.472745  0.527255\n",
       "1   yes       no  severe      normal  0.145872  0.854128\n",
       "2   yes     mild    mild      normal  0.245876  0.754124\n",
       "3    no     mild      no      normal  0.947347  0.052653\n",
       "4   yes   severe  severe      normal  0.284946  0.715054"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cold Predicted</th>\n",
       "      <th>Flu Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cold Actual</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flu Actual</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Cold Predicted  Flu Predicted\n",
       "Cold Actual               1              1\n",
       "Flu Actual                3              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Iteration 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cough</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Sore</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>flu</th>\n",
       "      <th>cold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>severe</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>0.247137</td>\n",
       "      <td>0.752863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>severe</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.033167</td>\n",
       "      <td>0.966833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.377663</td>\n",
       "      <td>0.622337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.998850</td>\n",
       "      <td>0.001150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>severe</td>\n",
       "      <td>severe</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.109139</td>\n",
       "      <td>0.890861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cough Headache    Sore Temperature       flu      cold\n",
       "0   yes   severe    mild        high  0.247137  0.752863\n",
       "1   yes       no  severe      normal  0.033167  0.966833\n",
       "2   yes     mild    mild      normal  0.377663  0.622337\n",
       "3    no     mild      no      normal  0.998850  0.001150\n",
       "4   yes   severe  severe      normal  0.109139  0.890861"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cold Predicted</th>\n",
       "      <th>Flu Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cold Actual</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flu Actual</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Cold Predicted  Flu Predicted\n",
       "Cold Actual               1              1\n",
       "Flu Actual                3              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using the training df\n",
    "attribute_column = list(training_df.columns)\n",
    "attribute_column.remove(\"class\")\n",
    "unsupervised_df = initialise_unsupervised_naive_bayes(training_df, \"class\")\n",
    "unsupervised_df[\"flu\"] = [0.6, 0.3, 0.1, 0.8, 0.4]\n",
    "unsupervised_df[\"cold\"] = [0.4, 0.7, 0.9, 0.2, 0.6]\n",
    "print(\"Iteration 0\")\n",
    "display(unsupervised_df)\n",
    "print(\"\\n\\n\")\n",
    "for i in range(ITERATION):\n",
    "    # Train and give prediction and calculate accuracy\n",
    "    print(\"Iteration {}\".format(i+1))\n",
    "    model = train_probability_unsupervised(training_df[\"class\"].unique(), attribute_column, unsupervised_df, \"class\")\n",
    "    predicted_test_result = predict_unsupervised(unsupervised_df, training_df[\"class\"].unique(), attribute_column, \"class\", model)\n",
    "    confusion_matrix = evaluate_unsupervised([\"flu\", \"cold\", \"flu\", \"cold\", \"flu\"], predicted_test_result, [\"cold\", \"flu\"])\n",
    "    display(unsupervised_df)\n",
    "    display(confusion_matrix)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions (you may respond in a cell or cells below):\n",
    "\n",
    "1. Since we’re starting off with random guesses, it might be surprising that the unsupervised NB works at all. Explain what characteristics of the data cause it to work pretty well (say, within 10% Accuracy of the supervised NB) most of the time; also, explain why it utterly fails sometimes.\n",
    "2. When evaluating supervised NB across the four different datasets, you will observe some variation in effectiveness (e.g. Accuracy). Explain what causes this variation. Describe and explain any particularly suprising results.\n",
    "3. Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out (hint: check out numpy.shuffle()) or cross–validation evaluation strategy. How does your estimate of Accuracy change, compared to testing on the training data? Explain why. (The result might surprise you!)\n",
    "4. Implement one of the advanced smoothing regimes (add-k, Good-Turing). Do you notice any variation in the predictions made by either the supervised or unsupervised NB classifiers? Explain why, or why not.\n",
    "5. The lecture suggests that deterministically labelling the instances in the initialisation phase of the unsupervised NB classifier “doesn’t work very well”. Confirm this for yourself, and then demonstrate why.\n",
    "6. Rather than evaluating the unsupervised NB classifier by assigning a class deterministically, instead calculate how far away the probabilistic estimate of the true class is from 1 (where we would be certain of the correct class), and take the average over the instances. Does this performance estimate change, as we alter the number of iterations in the method? Explain why.\n",
    "7. Explore what causes the unsupervised NB classifier to converge: what proportion of instances change their prediction from the random assignment, to the first iteration? From the first to the second? What is the latest iteration where you observe a prediction change? Make some conjecture(s) as to what is occurring here.\n",
    "\n",
    "Don't forget that groups of 1 student should respond to question (1), and one other question. Groups of 2 students should respond to question (1), and three other questions. Your responses should be about 100-200 words each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
