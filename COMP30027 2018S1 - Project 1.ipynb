{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: What is labelled data worth to Naive Bayes?\n",
    "---\n",
    "###### Student Name(s): Maleakhi Agung Wijaya, Chirag Rao Sahib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Path Constant\n",
    "BREAST_CANCER = \"2018S1-proj1_data/breast-cancer-dos.csv\"\n",
    "CAR = \"2018S1-proj1_data/car-dos.csv\"\n",
    "HYPOTHYROID = \"2018S1-proj1_data/hypothyroid-dos.csv\"\n",
    "MUSHROOM = \"2018S1-proj1_data/mushroom-dos.csv\"\n",
    "\n",
    "# Column name for each data set\n",
    "BREAST_CANCER_COLUMN = [\"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"node-caps\", \"deg-malig\", \"breast\", \"breast-quad\", \"irradiat\", \"class\"]\n",
    "CAR_COLUMN = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "HYPOTHYROID_COLUMN = [\"sex\", \"on_thyroxine\", \"query_on_thyroxine\", \"on_antithyroid_medication\", \"thyroid_surgery\", \"query_hypothyroid\", \"query_hyperthyroid\", \"pregnant\", \"sick\", \"tumor\", \"lithium\", \"goitre\", \"TSH_measured\", \"T3_measured\", \"TT4_measured\", \"T4U_measured\", \"FTI_measured\", \"TBG_measured\", \"class\"]\n",
    "MUSHROOM_COLUMN = [\"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\", \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\", \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"ring-number\", \"ring-type\", \"spore-print-color\", \"population\", \"habitat\", \"class\"]\n",
    "\n",
    "# Other Constant\n",
    "PRIOR_INDEX = 0\n",
    "POSTERIOR_INDEX = 1\n",
    "EPSILON = 0.000001 # Epsilon smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cough</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Sore</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>severe</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>flu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>severe</td>\n",
       "      <td>normal</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>flu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>severe</td>\n",
       "      <td>severe</td>\n",
       "      <td>normal</td>\n",
       "      <td>flu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cough Headache    Sore Temperature class\n",
       "0   yes   severe    mild        high   flu\n",
       "1   yes       no  severe      normal  cold\n",
       "2   yes     mild    mild      normal   flu\n",
       "3    no     mild      no      normal  cold\n",
       "4   yes   severe  severe      normal   flu"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used to check algorithm correctness\n",
    "training_df = pd.DataFrame(data={\"Headache\": [\"severe\", \"no\", \"mild\", \"mild\", \"severe\"], \"Sore\": [\"mild\", \"severe\", \"mild\", \"no\", \"severe\"], \"Temperature\":[\"high\", \"normal\", \"normal\", \"normal\", \"normal\"], \"Cough\": [\"yes\", \"yes\", \"yes\", \"no\", \"yes\"], \"class\":[\"flu\", \"cold\", \"flu\", \"cold\", \"flu\"]})\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cough</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Sore</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>severe</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no</td>\n",
       "      <td>severe</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cough Headache    Sore Temperature\n",
       "0    no     mild  severe      normal\n",
       "1    no   severe    mild        high"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(data={\"Headache\": [\"mild\", \"severe\"], \"Sore\": [\"severe\", \"mild\"], \"Temperature\": [\"normal\", \"high\"], \"Cough\":[\"no\", \"no\"]})\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "# @param data = csv data that will be opened\n",
    "# @param columns = new column name for header\n",
    "# @param eliminate = eliminate the missing/ ? instances (recommended if there are only few ? instances)\n",
    "# @return df = clean pandas dataframe object\n",
    "def preprocess(data, columns, eliminate=True):\n",
    "    # Read and add a header to the data frame\n",
    "    df = pd.read_csv(data, header=None)\n",
    "    df.columns = columns\n",
    "    \n",
    "    # If the parameter ignore is set to be false then we don't ignore\n",
    "    if (eliminate):\n",
    "        # Iterate through the dataframe and only append without missing value\n",
    "        # Capture the index of one with the missing values\n",
    "        for index, row in df.iterrows():\n",
    "            for att in row:\n",
    "                # If encounter missing values in the data, don't use that\n",
    "                if (att == \"?\"):\n",
    "                    df.drop(index, inplace=True)\n",
    "                    break\n",
    "    \n",
    "    # Return the clean data\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should build a supervised NB model and return a count\n",
    "# @param train_data = training data that are used to create the supervised NB classifier\n",
    "# @param class_label = column name of the class that we want to classify\n",
    "# @return count_prior = dictionary describing prior count of the class in training data\n",
    "# @return count_posterior = dictionary of dictionaries posterior count\n",
    "def train_count_supervised(train_data, class_label):\n",
    "    # Calculate prior (dictionary_prior)\n",
    "    # Initiate python dictionary with the number of class in the training data as it's key\n",
    "    count_prior = {}\n",
    "    for unique_class in train_data[class_label].unique():\n",
    "        count_prior[unique_class] = 0\n",
    "    \n",
    "    # Loop through the training data and get how many for every classes instance.\n",
    "    # Now we have the count prior class that are used for prediction\n",
    "    for index, row in train_data.iterrows():\n",
    "        count_prior[row[class_label]] += 1\n",
    "    \n",
    "    # Calculate count posterior (dictionary_posterior), the data structure used are dictionary\n",
    "    # of dictionary of dictionaries\n",
    "    count_posterior = {}\n",
    "    \n",
    "    # Setup the dictionary component\n",
    "    column_name = list(train_data.columns)\n",
    "    column_name.remove(class_label)\n",
    "    for col in column_name:\n",
    "        count_posterior[col] = {}\n",
    "        for unique_class in train_data[class_label].unique():\n",
    "            count_posterior[col][unique_class] = {}\n",
    "            for unique_col in train_data[col].unique():\n",
    "                count_posterior[col][unique_class][unique_col] = 0\n",
    "    \n",
    "    # Now use the training data to perform calculation\n",
    "    for index, row in train_data.iterrows():\n",
    "        for col in column_name:\n",
    "            count_posterior[col][row[class_label]][row[col]] += 1\n",
    "            \n",
    "    return((count_prior, count_posterior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should build supervised NB model and return a probability\n",
    "# @param train_data = training data that are used to create the supervised NB classifier\n",
    "# @param class_label = column name of the class that we want to classify\n",
    "# @return probability_prior = dictionary describing prior probability of the class in training data,\n",
    "# @return probability_posterior = dictionary of dictionaries posterior probability\n",
    "def train_probability_supervised(train_data, class_label):\n",
    "    (count_prior, count_posterior) = train_count_supervised(train_data, class_label)\n",
    "    \n",
    "    # Now calculate the probability of each instances, (i.e. 'Cough': {'flu': {'yes': 3, 'no': 0}, 'cold': {'yes': 1, 'no': 1}}\n",
    "    # will have P(cough = yes | flu) = 3/3, P(cough = no | flu) = 0/3 and P(cough = yes | cold) = 1/2, P(cough = no | cold) = 1/2\n",
    "    \n",
    "    # First calculate the prior probability of the class P(c)\n",
    "    probability_prior = {}\n",
    "    sum_instance = sum(count_prior.values())\n",
    "    for unique_class in train_data[class_label].unique():\n",
    "        probability_prior[unique_class] = count_prior[unique_class] / sum_instance\n",
    "        \n",
    "        # Perform epsilon smoothing\n",
    "        if (count_prior[unique_class] == 0):\n",
    "            probability_prior[unique_class] = EPSILON\n",
    "    \n",
    "    # Calculate the posterior probability\n",
    "    probability_posterior = count_posterior\n",
    "    column_name = list(train_data.columns)\n",
    "    column_name.remove(class_label)\n",
    "                \n",
    "    # Now calculate the posterior probability\n",
    "    for col in column_name:\n",
    "        for unique_class in train_data[class_label].unique():\n",
    "            sum_instance = sum(probability_posterior[col][unique_class].values())\n",
    "            for unique_col in train_data[col].unique():\n",
    "                probability_posterior[col][unique_class][unique_col] /= sum_instance\n",
    "                \n",
    "                # Perform epsilon smoothing\n",
    "                if (probability_posterior[col][unique_class][unique_col] == 0):\n",
    "                    probability_posterior[col][unique_class][unique_col] = EPSILON\n",
    "                \n",
    "            \n",
    "    return((probability_prior, probability_posterior))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should predict the class for a set of instances, based on a trained model \n",
    "# @param test_data = data to be tested\n",
    "# @param train_data = data used for setup such as finding all possible classes\n",
    "# @param class_label = attribute that we want to classify using naive bayes\n",
    "# @param model = tuple consisting probability_prior and probability_posterior. \n",
    "# Mainly use the train_probability_supervised instead of train_count_supervised\n",
    "# @return test_class = the class predicted by the naive bayes classifier\n",
    "def predict_supervised(test_data, train_data, class_label, model):\n",
    "    prior_probability = model[PRIOR_INDEX]\n",
    "    posterior_probability = model[POSTERIOR_INDEX]\n",
    "    test_class = [] # used to capture test result\n",
    "    \n",
    "    # Used for calculation purposes\n",
    "    column_name = list(train_data.columns)\n",
    "    column_name.remove(class_label)\n",
    "    \n",
    "    # Get the answer for every test instance\n",
    "    for index, row in test_data.iterrows():\n",
    "        # Initiate dictionary capturing the values calculated by naive bayes model\n",
    "        test_value = {}\n",
    "        for unique_class in train_data[class_label].unique():\n",
    "            test_value[unique_class] = 0\n",
    "\n",
    "        # Calculate for each class using the naive bayes model (log model for multiplication)\n",
    "        for unique_class in train_data[class_label].unique():\n",
    "            test_value[unique_class] = np.log(prior_probability[unique_class])\n",
    "            for col in column_name:\n",
    "                test_value[unique_class] += np.log(posterior_probability[col][unique_class][row[col]])\n",
    "            \n",
    "        # After calculating all of the possible class, we want to choose the maximum\n",
    "        maximum_class = (train_data[class_label].unique())[0]\n",
    "        maximum_value = test_value[maximum_class]\n",
    "        for key, value in test_value.items():\n",
    "            if (value > maximum_value):\n",
    "                maximum_value = value\n",
    "                maximum_class = key\n",
    "    \n",
    "        # Append result\n",
    "        test_class.append(maximum_class)\n",
    "    \n",
    "    # Return the classifier for the class\n",
    "    return test_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context \n",
    "def evaluate_supervised(true_test_result, predicted_test_result):\n",
    "    if (len(true_test_result) != len(predicted_test_result)):\n",
    "        print(\"Error, different length.\")\n",
    "    else:\n",
    "        # Measure accuracy\n",
    "        correct = 0\n",
    "        for i in range(len(true_test_result)):\n",
    "            if (true_test_result[i] == predicted_test_result[i]):\n",
    "                correct += 1\n",
    "            \n",
    "        accuracy = correct / len(true_test_result)\n",
    "        \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for breast cancer dataset is 0.7689530685920578.\n",
      "The accuracy for car dataset is 0.8738425925925926.\n",
      "The accuracy for hypothyroid dataset is 0.9517799352750809.\n",
      "The accuracy for mushroom dataset is 0.997165131112686.\n"
     ]
    }
   ],
   "source": [
    "# Using the breast cancer data\n",
    "df_breast_cancer = preprocess(BREAST_CANCER, BREAST_CANCER_COLUMN, eliminate=True)\n",
    "model_main = train_probability_supervised(df_breast_cancer, \"class\")\n",
    "predicted_test_result = predict_supervised(df_breast_cancer, df_breast_cancer, \"class\", model_main)\n",
    "print(\"The accuracy for breast cancer dataset is {}.\".format(evaluate_supervised(list(df_breast_cancer[\"class\"]), predicted_test_result)))\n",
    "\n",
    "# Using car data\n",
    "df_car = preprocess(CAR, CAR_COLUMN, eliminate=True)\n",
    "model_main = train_probability_supervised(df_car, \"class\")\n",
    "predicted_test_result = predict_supervised(df_car, df_car, \"class\", model_main)\n",
    "print(\"The accuracy for car dataset is {}.\".format(evaluate_supervised(list(df_car[\"class\"]), predicted_test_result)))\n",
    "\n",
    "# Using the breast cancer data\n",
    "df_hypo = preprocess(HYPOTHYROID, HYPOTHYROID_COLUMN, eliminate=True)\n",
    "model_main = train_probability_supervised(df_hypo, \"class\")\n",
    "predicted_test_result = predict_supervised(df_hypo, df_hypo, \"class\", model_main)\n",
    "print(\"The accuracy for hypothyroid dataset is {}.\".format(evaluate_supervised(list(df_hypo[\"class\"]), predicted_test_result)))\n",
    "\n",
    "# Using the breast cancer data\n",
    "df_mushroom = preprocess(MUSHROOM, MUSHROOM_COLUMN, eliminate=True)\n",
    "model_main = train_probability_supervised(df_mushroom, \"class\")\n",
    "predicted_test_result = predict_supervised(df_mushroom, df_mushroom, \"class\", model_main)\n",
    "print(\"The accuracy for mushroom dataset is {}.\".format(evaluate_supervised(list(df_mushroom[\"class\"]), predicted_test_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Unsupervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Cough Headache    Sore Temperature       flu      cold\n",
      "0   yes   severe    mild        high  0.133589  0.866411\n",
      "1   yes       no  severe      normal  0.311727  0.688273\n",
      "2   yes     mild    mild      normal  0.707640  0.292360\n",
      "3    no     mild      no      normal  0.345900  0.654100\n",
      "4   yes   severe  severe      normal  0.104684  0.895316\n"
     ]
    }
   ],
   "source": [
    "# This function initialise the distribution randomly to the dataframe to begin the unsupervised\n",
    "# calculation.\n",
    "# @param dataset = dataframe of the dataset\n",
    "# @param class_label = class that we will use the classification on\n",
    "# @return unsupervised_dataset = dataset that have been appended by the distribution columns\n",
    "def initialise_unsupervised_naive_bayes(dataset, class_label):\n",
    "    # First remove the class label and put that on the columns so that we can assign a distribution\n",
    "    class_column = list(dataset[class_label].unique())\n",
    "    last_class = class_column[-1]\n",
    "    unsupervised_dataset = dataset.drop([\"class\"], axis=1)\n",
    "    \n",
    "    # Add a column to the dataset according to random distribution (initialisation phase)\n",
    "    row_instance = unsupervised_dataset.shape[0]\n",
    "    for unique_class in class_column:\n",
    "        unsupervised_dataset[unique_class] = [0 for i in range(row_instance)]\n",
    "    \n",
    "    # Add random value to the dataset\n",
    "    for index, row in unsupervised_dataset.iterrows():\n",
    "        max_probability = 1\n",
    "        for unique_class in class_column:\n",
    "            # Assign the remaining probability to the last class\n",
    "            if (unique_class == last_class):\n",
    "                unsupervised_dataset.loc[index, unique_class] = max_probability\n",
    "            else:\n",
    "                unsupervised_dataset.loc[index, unique_class] = random.uniform(0, max_probability)\n",
    "                max_probability -= unsupervised_dataset.loc[index, unique_class]\n",
    "    \n",
    "    return unsupervised_dataset\n",
    "    \n",
    "unsupervised_df = initialise_unsupervised_naive_bayes(training_df, \"class\")\n",
    "print(unsupervised_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'cold': 3.396459833903957, 'flu': 1.6035401660960429},\n",
       " {'Cough': {'cold': {'no': 0.6540996005775863, 'yes': 2.742360233326371},\n",
       "   'flu': {'no': 0.3459003994224137, 'yes': 1.2576397666736292}},\n",
       "  'Headache': {'cold': {'mild': 0.9464594317940587,\n",
       "    'no': 0.6882732249102493,\n",
       "    'severe': 1.7617271771996492},\n",
       "   'flu': {'mild': 1.0535405682059413,\n",
       "    'no': 0.31172677508975066,\n",
       "    'severe': 0.2382728228003509}},\n",
       "  'Sore': {'cold': {'mild': 1.1587710543506335,\n",
       "    'no': 0.6540996005775863,\n",
       "    'severe': 1.5835891789757373},\n",
       "   'flu': {'mild': 0.8412289456493666,\n",
       "    'no': 0.3459003994224137,\n",
       "    'severe': 0.41641082102426263}},\n",
       "  'Temperature': {'cold': {'high': 0.8664112231341611,\n",
       "    'normal': 2.530048610769796},\n",
       "   'flu': {'high': 0.13358877686583892, 'normal': 1.469951389230204}}})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This function should build an unsupervised NB model and return a count\n",
    "# @param class_column = possible class name (weak unsupervised model)\n",
    "# @param attribute_column = attributes that are used for calculation\n",
    "# @param train_data = training data that are used to create the unsupervised NB classifier (format after running initialise_unsupervised_naive_bayes function)\n",
    "# @param class_label = column name of the class that we want to classify\n",
    "# @return count_prior = dictionary describing prior count of the class in training data\n",
    "# @return count_posterior = dictionary of dictionaries posterior count\n",
    "def train_count_unsupervised(class_column, attribute_column, train_data , class_label):\n",
    "    # Calculate prior (dictionary_prior)\n",
    "    # Initiate python dictionary with the number of class in the training data as it's key\n",
    "    count_prior = {}\n",
    "    for unique_class in class_column:\n",
    "        count_prior[unique_class] = 0\n",
    "    \n",
    "    # Loop through the training data and sum the probability\n",
    "    for index, row in train_data.iterrows():\n",
    "        for unique_class in class_column:\n",
    "            count_prior[unique_class] += row[unique_class]\n",
    "    \n",
    "    # Calculate count posterior (dictionary_posterior), the data structure used are dictionary\n",
    "    # of dictionary of dictionaries\n",
    "    count_posterior = {}\n",
    "    \n",
    "    # Setup the dictionary component\n",
    "    for col in attribute_column:\n",
    "        count_posterior[col] = {}\n",
    "        for unique_class in class_column:\n",
    "            count_posterior[col][unique_class] = {}\n",
    "            for unique_col in train_data[col].unique():\n",
    "                count_posterior[col][unique_class][unique_col] = 0\n",
    "    \n",
    "    # Now use the training data to perform calculation\n",
    "    for index, row in train_data.iterrows():\n",
    "        for col in attribute_column:\n",
    "            for unique_class in class_column:\n",
    "                count_posterior[col][unique_class][row[col]] += row[unique_class]\n",
    "   \n",
    "    return((count_prior, count_posterior))\n",
    "\n",
    "attribute_column = list(training_df.columns)\n",
    "attribute_column.remove(\"class\")\n",
    "train_count_unsupervised(training_df[\"class\"].unique(), attribute_column, unsupervised_df, \"class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should predict the class distribution for a set of instances, based on a trained model\n",
    "def predict_unsupervised():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in an unsupervised manner\n",
    "def evaluate_unsupervised():\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions (you may respond in a cell or cells below):\n",
    "\n",
    "1. Since we’re starting off with random guesses, it might be surprising that the unsupervised NB works at all. Explain what characteristics of the data cause it to work pretty well (say, within 10% Accuracy of the supervised NB) most of the time; also, explain why it utterly fails sometimes.\n",
    "2. When evaluating supervised NB across the four different datasets, you will observe some variation in effectiveness (e.g. Accuracy). Explain what causes this variation. Describe and explain any particularly suprising results.\n",
    "3. Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out (hint: check out numpy.shuffle()) or cross–validation evaluation strategy. How does your estimate of Accuracy change, compared to testing on the training data? Explain why. (The result might surprise you!)\n",
    "4. Implement one of the advanced smoothing regimes (add-k, Good-Turing). Do you notice any variation in the predictions made by either the supervised or unsupervised NB classifiers? Explain why, or why not.\n",
    "5. The lecture suggests that deterministically labelling the instances in the initialisation phase of the unsupervised NB classifier “doesn’t work very well”. Confirm this for yourself, and then demonstrate why.\n",
    "6. Rather than evaluating the unsupervised NB classifier by assigning a class deterministically, instead calculate how far away the probabilistic estimate of the true class is from 1 (where we would be certain of the correct class), and take the average over the instances. Does this performance estimate change, as we alter the number of iterations in the method? Explain why.\n",
    "7. Explore what causes the unsupervised NB classifier to converge: what proportion of instances change their prediction from the random assignment, to the first iteration? From the first to the second? What is the latest iteration where you observe a prediction change? Make some conjecture(s) as to what is occurring here.\n",
    "\n",
    "Don't forget that groups of 1 student should respond to question (1), and one other question. Groups of 2 students should respond to question (1), and three other questions. Your responses should be about 100-200 words each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
