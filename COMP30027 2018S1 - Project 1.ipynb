{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: What is labelled data worth to Naive Bayes?\n",
    "---\n",
    "###### Student Name(s): Maleakhi Agung Wijaya, Chirag Rao Sahib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Library\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Path Constant\n",
    "BREAST_CANCER = \"2018S1-proj1_data/breast-cancer-dos.csv\"\n",
    "CAR = \"2018S1-proj1_data/car-dos.csv\"\n",
    "HYPOTHYROID = \"2018S1-proj1_data/hypothyroid-dos.csv\"\n",
    "MUSHROOM = \"2018S1-proj1_data/mushroom-dos.csv\"\n",
    "\n",
    "# Column name for each data set\n",
    "BREAST_CANCER_COLUMN = [\"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"node-caps\", \"deg-malig\", \"breast\", \"breast-quad\", \"irradiat\", \"class\"]\n",
    "CAR_COLUMN = [\"buying\", \"maint\", \"doors\", \"persons\", \"lug_boot\", \"safety\", \"class\"]\n",
    "HYPOTHYROID_COLUMN = [\"sex\", \"on_thyroxine\", \"query_on_thyroxine\", \"on_antithyroid_medication\", \"thyroid_surgery\", \"query_hypothyroid\", \"query_hyperthyroid\", \"pregnant\", \"sick\", \"tumor\", \"lithium\", \"goitre\", \"TSH_measured\", \"T3_measured\", \"TT4_measured\", \"T4U_measured\", \"FTI_measured\", \"TBG_measured\", \"class\"]\n",
    "MUSHROOM_COLUMN = [\"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises\", \"odor\", \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\", \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"ring-number\", \"ring-type\", \"spore-print-color\", \"population\", \"habitat\", \"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cough</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Sore</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yes</td>\n",
       "      <td>severe</td>\n",
       "      <td>mild</td>\n",
       "      <td>high</td>\n",
       "      <td>flu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>severe</td>\n",
       "      <td>normal</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yes</td>\n",
       "      <td>mild</td>\n",
       "      <td>mild</td>\n",
       "      <td>normal</td>\n",
       "      <td>flu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no</td>\n",
       "      <td>mild</td>\n",
       "      <td>no</td>\n",
       "      <td>normal</td>\n",
       "      <td>cold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yes</td>\n",
       "      <td>severe</td>\n",
       "      <td>severe</td>\n",
       "      <td>normal</td>\n",
       "      <td>flu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Cough Headache    Sore Temperature class\n",
       "0   yes   severe    mild        high   flu\n",
       "1   yes       no  severe      normal  cold\n",
       "2   yes     mild    mild      normal   flu\n",
       "3    no     mild      no      normal  cold\n",
       "4   yes   severe  severe      normal   flu"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used to check algorithm correctness\n",
    "df = pd.DataFrame(data={\"Headache\": [\"severe\", \"no\", \"mild\", \"mild\", \"severe\"], \"Sore\": [\"mild\", \"severe\", \"mild\", \"no\", \"severe\"], \"Temperature\":[\"high\", \"normal\", \"normal\", \"normal\", \"normal\"], \"Cough\": [\"yes\", \"yes\", \"yes\", \"no\", \"yes\"], \"class\":[\"flu\", \"cold\", \"flu\", \"cold\", \"flu\"]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "# @param data = csv data that will be opened\n",
    "# @param columns = new column name for header\n",
    "# @param eliminate = eliminate the missing/ ? instances (recommended if there are only few ? instances)\n",
    "# @return df = clean pandas dataframe object\n",
    "def preprocess(data, columns, eliminate=True):\n",
    "    # Read and add a header to the data frame\n",
    "    df = pd.read_csv(data, header=None)\n",
    "    df.columns = columns\n",
    "    \n",
    "    # If the parameter ignore is set to be false then we don't ignore\n",
    "    if (eliminate):\n",
    "        # Iterate through the dataframe and only append without missing value\n",
    "        # Capture the index of one with the missing values\n",
    "        for index, row in df.iterrows():\n",
    "            for att in row:\n",
    "                # If encounter missing values in the data, don't use that\n",
    "                if (att == \"?\"):\n",
    "                    df.drop(index, inplace=True)\n",
    "                    break\n",
    "    \n",
    "    # Return the clean data\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This function should build a supervised NB model and return a count\n",
    "# @param train_data = training data that are used to create the supervised NB classifier\n",
    "# @param class_label = column name of the class that we want to classify\n",
    "# @return count_prior = dictionary describing prior count of the class in training data, \n",
    "#         count_posterior = dictionary of dictionaries posterior count\n",
    "def train_count_supervised(train_data, class_label):\n",
    "    # Calculate prior (dictionary_prior)\n",
    "    # Initiate python dictionary with the number of class in the training data as it's key\n",
    "    count_prior = {}\n",
    "    for unique_class in train_data[class_label].unique():\n",
    "        count_prior[unique_class] = 0\n",
    "    \n",
    "    # Loop through the training data and get how many for every classes instance.\n",
    "    # Now we have the count prior class that are used for prediction\n",
    "    for index, row in train_data.iterrows():\n",
    "        count_prior[row[class_label]] += 1\n",
    "    \n",
    "    # Calculate count posterior (dictionary_posterior), the data structure used are dictionary\n",
    "    # of dictionary of dictionaries\n",
    "    count_posterior = {}\n",
    "    \n",
    "    # Setup the dictionary component\n",
    "    column_name = list(train_data.columns)\n",
    "    column_name.remove(class_label)\n",
    "    for col in column_name:\n",
    "        count_posterior[col] = {}\n",
    "        for unique_class in train_data[class_label].unique():\n",
    "            count_posterior[col][unique_class] = {}\n",
    "            for unique_col in train_data[col].unique():\n",
    "                count_posterior[col][unique_class][unique_col] = 0\n",
    "    \n",
    "    # Now use the training data to perform calculation\n",
    "    for index, row in train_data.iterrows():\n",
    "        for col in column_name:\n",
    "            count_posterior[col][row[class_label]][row[col]] += 1\n",
    "            \n",
    "    return((count_prior, count_posterior))\n",
    "\n",
    "# This function should build supervised NB model and return a probability\n",
    "# @param train_data = training data that are used to create the supervised NB classifier\n",
    "# @param class_label = column name of the class that we want to classify\n",
    "# @return probability_prior = dictionary describing prior probability of the class in training data,\n",
    "#         probability_posterior = dictionary of dictionaries posterior probability\n",
    "def train_probability_supervised(train_data, class_label):\n",
    "    (count_prior, count_posterior) = train_count_supervised(train_data, class_label)\n",
    "    print(count_posterior)\n",
    "    \n",
    "    # Now calculate the probability of each instances, (i.e. 'Cough': {'flu': {'yes': 3, 'no': 0}, 'cold': {'yes': 1, 'no': 1}}\n",
    "    # will have P(cough = yes | flu) = 3/3, P(cough = no | flu) = 0/3 and P(cough = yes | cold) = 1/2, P(cough = no | cold) = 1/2\n",
    "    \n",
    "    # First calculate the prior probability of the class P(c)\n",
    "    probability_prior = {}\n",
    "    sum_instance = sum(count_prior.values())\n",
    "    for unique_class in train_data[class_label].unique():\n",
    "        probability_prior[unique_class] = count_prior[unique_class] / sum_instance\n",
    "    \n",
    "    # Calculate the posterior probability\n",
    "    probability_posterior = count_posterior\n",
    "    column_name = list(train_data.columns)\n",
    "    column_name.remove(class_label)\n",
    "                \n",
    "    # Now calculate the posterior probability\n",
    "    for col in column_name:\n",
    "        for unique_class in train_data[class_label].unique():\n",
    "            sum_instance = sum(probability_posterior[col][unique_class].values())\n",
    "            for unique_col in train_data[col].unique():\n",
    "                probability_posterior[col][unique_class][unique_col] /= sum_instance\n",
    "            \n",
    "    return((probability_prior, probability_posterior))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should predict the class for a set of instances, based on a trained model \n",
    "def predict_supervised():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in a supervised context \n",
    "def evaluate_supervised():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should build an unsupervised NB model \n",
    "def train_unsupervised():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should predict the class distribution for a set of instances, based on a trained model\n",
    "def predict_unsupervised():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This function should evaluate a set of predictions, in an unsupervised manner\n",
    "def evaluate_unsupervised():\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions (you may respond in a cell or cells below):\n",
    "\n",
    "1. Since we’re starting off with random guesses, it might be surprising that the unsupervised NB works at all. Explain what characteristics of the data cause it to work pretty well (say, within 10% Accuracy of the supervised NB) most of the time; also, explain why it utterly fails sometimes.\n",
    "2. When evaluating supervised NB across the four different datasets, you will observe some variation in effectiveness (e.g. Accuracy). Explain what causes this variation. Describe and explain any particularly suprising results.\n",
    "3. Evaluating the model on the same data that we use to train the model is considered to be a major mistake in Machine Learning. Implement a hold–out (hint: check out numpy.shuffle()) or cross–validation evaluation strategy. How does your estimate of Accuracy change, compared to testing on the training data? Explain why. (The result might surprise you!)\n",
    "4. Implement one of the advanced smoothing regimes (add-k, Good-Turing). Do you notice any variation in the predictions made by either the supervised or unsupervised NB classifiers? Explain why, or why not.\n",
    "5. The lecture suggests that deterministically labelling the instances in the initialisation phase of the unsupervised NB classifier “doesn’t work very well”. Confirm this for yourself, and then demonstrate why.\n",
    "6. Rather than evaluating the unsupervised NB classifier by assigning a class deterministically, instead calculate how far away the probabilistic estimate of the true class is from 1 (where we would be certain of the correct class), and take the average over the instances. Does this performance estimate change, as we alter the number of iterations in the method? Explain why.\n",
    "7. Explore what causes the unsupervised NB classifier to converge: what proportion of instances change their prediction from the random assignment, to the first iteration? From the first to the second? What is the latest iteration where you observe a prediction change? Make some conjecture(s) as to what is occurring here.\n",
    "\n",
    "Don't forget that groups of 1 student should respond to question (1), and one other question. Groups of 2 students should respond to question (1), and three other questions. Your responses should be about 100-200 words each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
